# GalaxyCo.ai 2.0 - Project Rules

**Last Updated**: January 10, 2025  
**Project**: GalaxyCo.ai 2.0 - Make multi-agent AI useful in minutes  
**Current Phase**: Phase 9B - Live Execution & Testing

---

## ğŸ¯ Project Overview

GalaxyCo.ai is a multi-agent AI platform where users get personalized dashboards with AI agent "Packs" that deliver measurable outcomes from Day 1.

**Key Architecture**:

- **Frontend**: Next.js 14 (App Router) + React 18 + TypeScript + Tailwind CSS
- **Backend**: NestJS (REST + WebSocket) + Python agents (FastAPI + LangGraph)
- **Database**: Postgres with pgvector (Neon)
- **Cache**: Redis (Upstash)
- **Auth**: Clerk
- **Hosting**: Vercel (web) + AWS ECS (api/agents)
- **Monorepo**: Turborepo + pnpm workspaces

---

## ğŸ“ Repository Structure

```
galaxyco-ai-2.0/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/              # Next.js frontend (Vercel)
â”‚   â””â”€â”€ api/              # NestJS backend (AWS ECS)
â”œâ”€â”€ services/
â”‚   â””â”€â”€ agents/           # Python agents (AWS ECS)
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ database/         # Shared database package
â”‚   â”œâ”€â”€ ui/               # Shared React components
â”‚   â””â”€â”€ config/           # Shared configs
â”œâ”€â”€ docs/                 # Comprehensive documentation
â”œâ”€â”€ scripts/              # Utility scripts
â””â”€â”€ infra/terraform/      # Infrastructure as Code
```

---

## ğŸ” Security & Best Practices

### Environment Variables

- **NEVER** commit secrets to git
- **NEVER** print environment variable values in terminal output or logs
- Always reference secrets by name only and mask sensitive values
- Store production secrets in AWS Secrets Manager
- Use `.env.local` for local development only

### Multi-tenancy

- **ALWAYS** include `tenant_id` (or `workspace_id`) filter in WHERE clauses
- Never expose data across tenant boundaries
- Use row-level security policies where applicable
- Validate tenant_id matches authenticated user's tenant
- Log any cross-tenant data access attempts as security incidents

### Database Migrations (Drizzle)

1. Create migrations: `npm run db:migration:create -- migration_name`
2. Review generated SQL before applying
3. Test migration on dev environment first: `npm run db:migrate`
4. Include rollback plan in migration comments
5. Never modify existing migrationsâ€”create new ones for changes
6. Naming convention: `YYYYMMDD_descriptive_name.sql`

---

## ğŸ¤– AI Gateway Service

### Always Use AI Gateway

**NEVER** call AI providers (OpenAI, Anthropic) directly. Always use the centralized AI Gateway service.

```typescript
import { AIGatewayService } from "@/lib/ai-gateway";

const response = await AIGatewayService.generateText({
  tenantId: "workspace_123",
  userId: "user_456",
  agentId: "agent_789",
  model: "gpt-4o-mini",
  messages: [{ role: "user", content: "Hello!" }],
});
```

**Benefits**:

- âœ… Automatic cost tracking
- âœ… Comprehensive logging (tenant, user, agent)
- âœ… Error handling & retry support
- âœ… Performance monitoring

**Reference**: `docs/AI_GATEWAY_QUICK_REF.md`

---

## ğŸ’» Development Workflow

### Before Making Code Changes

Run health checks to ensure codebase is clean:

```bash
# From apps/web
pnpm typecheck    # TypeScript type checking
pnpm lint         # ESLint
```

**Block changes if any health checks fail.**

### Agent Execution Architecture âœ… NEW

The platform supports both **mock** and **live** agent execution:

```
TestPanel (React) â†’ /api/agents/[id]/execute â†’ Python FastAPI â†’ AI Providers
     â”‚                        â”‚                      â”‚
     â”‚                        â”œâ”€ Mock Mode          â”‚
     â”‚                        â””â”€ Live Mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â””â”€ Rich UI with metrics, error handling, mode toggle
```

**Mock Mode**: Returns deterministic responses without calling AI providers  
**Live Mode**: Routes through Python service using LangChain + OpenAI/Anthropic

**Key Files**:

- `apps/web/components/agents/TestPanel.tsx` - Frontend execution interface
- `apps/web/app/api/agents/[id]/execute/route.ts` - API endpoint with mode switching
- `services/agents/app.py` - Python FastAPI service for live execution
- `apps/web/lib/actions/agent-actions.ts` - Unified execution client

**Features**:

- âœ… Multi-tenant security (workspace isolation)
- âœ… Real-time metrics (tokens, cost, latency)
- âœ… Professional UI with loading states
- âœ… Comprehensive error handling
- âœ… Mobile-responsive test panel

### Git Commit Standards

Follow Conventional Commits format:

**Format**: `type(scope): message`

**Types**: `feat`, `fix`, `docs`, `refactor`, `test`, `chore`

**Scopes**: `web`, `api`, `agents`, `db`, `infra`, `docs`

**Examples**:

- `feat(web): add agent builder visual editor`
- `fix(api): handle missing workspace_id in agent execution`
- `docs(readme): update AI Gateway usage instructions`

### Git Configuration

- **Username**: `galaxy-co-ai`
- **Organization**: `galaxyco-ai`

---

## ğŸš€ Deployment

### Pre-Deployment Checklist

Before deploying to production:

1. âœ… Verify all smoke tests pass on staging
2. âœ… Check Sentry for recent errors in staging
3. âœ… Confirm database migrations applied successfully to staging
4. âœ… Review agent performance metrics (success rate, avg duration)
5. âœ… Have rollback plan ready (documented in workflow)
6. âœ… Notify team in Discord #deployments channel

**NEVER** deploy on Fridays after 2pm or before major holidays.

### Deployment Targets

- **Vercel**: Frontend (apps/web) - Auto-deploys from `main` and `develop`
- **Project Name**: `galaxyco-ai-platform`
- **AWS ECS**: Backend (apps/api) + Agents (services/agents)

### Confirmation for Destructive Operations

Always confirm before executing:

- Database resets
- File deletions
- Production deployments
- Cache clearing operations

---

## ğŸ§ª Testing & Quality

### Test Coverage Requirements

- All new features must include tests
- Test agents with mock data before connecting real integrations
- Run full test suite before PRs: `pnpm test`

### Code Quality Tools

- **Linting**: `pnpm lint`
- **Type Checking**: `pnpm typecheck`
- **Formatting**: Prettier (auto-format on save)

---

## ğŸ“š Documentation

### Quick Documentation Reference

- **Setup**: `docs/setup/QUICK_START.md`
- **AI Gateway**: `docs/AI_GATEWAY_QUICK_REF.md`
- **Development**: `docs/development/internal_dev_workflow_warp_6.md`
- **Deployment**: `docs/deployment/DEPLOYMENT_GUIDE.md`
- **Project Status**: `docs/planning/PROJECT_STATUS.md`
- **Working Docs**: `docs/working/INDEX.md` (collaboration system)

### AI Collaboration on Documentation

**CRITICAL**: AI is a critical advisor, not a blind implementer.

**Working Docs System** (`docs/working/`):

1. **User creates** research/docs in `drafts/` - capture everything liberally
2. **AI revises** critically - filters noise, adds analysis, moves to `reviewed/`
3. **User approves** - reviews AI's judgment and recommendations
4. **AI integrates** - creates artifacts and places in proper locations

**AI Must**:

- âœ… Analyze research critically (not implement everything found)
- âœ… Filter what fits our project stage (MVP vs V1 vs V2)
- âœ… Challenge ideas that don't fit our architecture
- âœ… Recommend with clear reasoning (Implement/Adapt/Defer/Skip)
- âœ… Flag questions requiring human judgment
- âœ… Revise documents to meet quality standards before integration

**Reference**: `docs/working/AI-COLLABORATION-PRINCIPLES.md`

### When to Update Docs

Update documentation when:

- âœ… New features implemented
- âœ… Architecture decisions made
- âœ… Process changes
- âœ… Troubleshooting guides needed
- âœ… Session handoffs
- âœ… Research findings (use `docs/working/` system)

### Documentation Format

- Use clear, step-by-step instructions
- Include code examples
- Collapse verbose logs to essential information
- Always show diffs for file changes
- Format command outputs for readability

---

## ğŸ¨ Design & UI Standards

### Visual Style

- **Theme**: Clean, minimal, enterprise-professional hybrid
- **Default**: Light theme with optional dark mode
- **Colors**: Cool tones with neutral grayscale base + blue-purple-teal accents
- **Components**: Card-based units, rounded corners, subtle dividers, medium shadows

### Inspirations

- StackAI (enterprise polish)
- OpenSea (card-driven discovery)
- OpenAI Agent Builder (simplicity)
- Sider (knowledge UI)
- Vercel (dashboard aesthetics)

---

## ğŸ”§ Development Environment

### Required Tools

- **Node.js**: 20+
- **pnpm**: 9+
- **Python**: 3.11+
- **Git**: Latest
- **Terminal**: Warp (preferred)

### Package Manager

**ALWAYS use pnpm**, never npm or yarn.

```bash
# Install dependencies
pnpm install

# Run dev servers
pnpm dev

# Build all packages
pnpm build
```

---

## ğŸš« What NOT to Do

### Avoid These Patterns

- âŒ Direct AI provider calls (use AI Gateway)
- âŒ Hard-coded API keys (use environment variables)
- âŒ Cross-tenant data exposure
- âŒ Committing secrets to git
- âŒ Modifying existing database migrations
- âŒ Deploying without running health checks
- âŒ Using npm or yarn (use pnpm)

### Legacy References

- âŒ Do NOT reference "Rise Roofing" - this is from a past project version
- âŒ Do NOT use outdated agent patterns - follow AI Gateway standards

### AI Collaboration Anti-Patterns

- âŒ Do NOT implement everything from research docs without critical analysis
- âŒ Do NOT skip the working docs review process (`docs/working/`)
- âŒ Do NOT assume all findings are relevant to current project stage

---

## ğŸ“Š Project Metadata

- **Current Phase**: Phase 9B - Live Execution & Testing
- **Repository**: `galaxyco-ai-2.0`
- **Organization**: `galaxyco-ai`
- **Primary Developer**: galaxy-co-ai
- **Development Hours**: High intensity (70 hrs/week target)

---

## ğŸ¤ Collaboration Workflow

### Session Management

- Track sprint/phase durations for KPIs
- Update handoff documents for session continuity
- Maintain context across Warp chat sessions

### Review Step Template

During reviews, provide:

1. âœ… To-do list of actions to test
2. âœ… Expected outcomes
3. âœ… Quick turnaround notes (what works, what doesn't)

---

## ğŸ¯ Project Goals

### Primary Objectives

1. Build polished dashboard environment (2-3 day sprints)
2. Phased feature rollout for consistent user upgrades
3. No corner-cutting - production-grade quality always
4. Budget-conscious ($200-$300/month post-setup)
5. AI that saves and recalls important project details

### Success Metrics

- **WSAO**: Weekly Successful Agent Outcomes
- Fast deployment cycles
- Clean, maintainable codebase
- Comprehensive documentation
- Excellent user experience

---

**Built with â¤ï¸ to make multi-agent AI useful in minutes**
